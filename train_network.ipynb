{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "from six.moves import urllib\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import *\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous char_idx\n"
     ]
    }
   ],
   "source": [
    "# Get text data from the three Lord of the Rings books\n",
    "path = 'input.txt'\n",
    "if not os.path.isfile(path):\n",
    "  urllib.request.urlretrieve(\"https://gist.githubusercontent.com/Blabby/eb5064cdc9f6b55f10a06bb2aabd2b04/raw/780dc55ed24122c615557981441c8a811905d4de/LOR_input_c.txt\", path)\n",
    "\n",
    "# Get pickle file containing the dictionary that maps characters to numbers\n",
    "char_idx_file = 'char_idx_LOR.pickle'\n",
    "char_idx = None\n",
    "\n",
    "if os.path.isfile(char_idx_file):\n",
    "  print('Loading previous char_idx')\n",
    "  char_idx = pickle.load(open(char_idx_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n",
      "Text total length: 2,528,442\n",
      "Distinct chars   : 43\n",
      "Total sequences  : 842,806\n"
     ]
    }
   ],
   "source": [
    "# Create char_idx and X, Y data\n",
    "maxlen = 25\n",
    "X, Y, char_idx = textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3)\n",
    "\n",
    "pickle.dump(char_idx, open(char_idx_file,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\x80': 38, '\\n': 0, '\\x99': 40, '\\x98': 39, '\\x9c': 41, '!': 2, ' ': 1, '\"': 3, \"'\": 4, ')': 6, '(': 5, '-': 8, ',': 7, '.': 9, ';': 10, '?': 11, '\\xe2': 42, 'a': 12, 'c': 14, 'b': 13, 'e': 16, 'd': 15, 'g': 18, 'f': 17, 'i': 20, 'h': 19, 'k': 22, 'j': 21, 'm': 24, 'l': 23, 'o': 26, 'n': 25, 'q': 28, 'p': 27, 's': 30, 'r': 29, 'u': 32, 't': 31, 'w': 34, 'v': 33, 'y': 36, 'x': 35, 'z': 37}\n"
     ]
    }
   ],
   "source": [
    "print(char_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create network layers\n",
    "g = tflearn.input_data([None, maxlen, len(char_idx)])\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.fully_connected(g, len(char_idx), activation='softmax')\n",
    "g = tflearn.regression(g, optimizer='adam', loss='categorical_crossentropy',\n",
    "                       learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = tflearn.SequenceGenerator(g, dictionary=char_idx,\n",
    "                              seq_maxlen=maxlen,\n",
    "                              clip_gradients=10.0,\n",
    "                              checkpoint_path='model_LOR',\n",
    "                              tensorboard_verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4530  | total loss: \u001b[1m\u001b[32m1.77558\u001b[0m\u001b[0m | time: 1.860s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 001 | loss: 1.77558 -- iter: 579840/716385\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "m.fit(X, Y, validation_set=0.15, batch_size=128, n_epoch=10, snapshot_step=2000, run_id='LOR_test')\n",
    "\n",
    "# Save the trained neural network\n",
    "m.save('LOR_network.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- Export from Google Data ---\n",
    "# http://stackoverflow.com/questions/35719627/how-do-i-quickly-get-data-out-of-a-google-cloud-datalab-notebook\n",
    "\n",
    "from datalab.context import Context\n",
    "import datalab.storage as storage\n",
    "\n",
    "sample_bucket_name = Context.default().project_id + '-datalab-example'\n",
    "sample_bucket_path = 'gs://' + sample_bucket_name\n",
    "\n",
    "sample_bucket = storage.Bucket(sample_bucket_name)\n",
    "\n",
    "# Create storage bucket if it does not exist\n",
    "if not sample_bucket.exists():\n",
    "    sample_bucket.create()\n",
    "\n",
    "# Write an item to the storage bucket\n",
    "# sample_item = sample_bucket.item('stringtofile.txt')\n",
    "# sample_item.write_to('This is a string', 'text/plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://LOR_prediction.tflearn [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 61.3 MiB]                                                \r",
      "-\r",
      "- [0 files][ 37.1 MiB/ 61.3 MiB]                                                \r",
      "\\\r",
      "\\ [1 files][ 61.3 MiB/ 61.3 MiB]                                                \r",
      "|\r\n",
      "Operation completed over 1 objects/61.3 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp 'LOR_network.tflearn' gs://neural-152015-datalab-example/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
